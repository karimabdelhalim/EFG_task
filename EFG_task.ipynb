{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tXk17SxDNyVt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YD5cWbmJN4DW",
        "outputId": "55c49678-b834-478c-87fc-5b882226e6ea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.3.10\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Wk0juKFBEkR",
        "outputId": "5fe27e38-6654-4398-80c4-b777122353ae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras_ocr\n",
            "  Downloading keras_ocr-0.9.3-py3-none-any.whl (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: editdistance in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (0.6.2)\n",
            "Collecting efficientnet==1.0.0 (from keras_ocr)\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting essential_generators (from keras_ocr)\n",
            "  Downloading essential_generators-1.0-py3-none-any.whl (9.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (4.51.0)\n",
            "Requirement already satisfied: imgaug in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (0.4.0)\n",
            "Collecting pyclipper (from keras_ocr)\n",
            "  Downloading pyclipper-1.3.0.post5-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (908 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m908.3/908.3 kB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: shapely in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (2.0.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from keras_ocr) (4.66.4)\n",
            "Collecting validators (from keras_ocr)\n",
            "  Downloading validators-0.28.1-py3-none-any.whl (39 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7 (from efficientnet==1.0.0->keras_ocr)\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from efficientnet==1.0.0->keras_ocr) (0.19.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.15 in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (1.11.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (9.4.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (3.7.1)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (4.8.0.76)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.10/dist-packages (from imgaug->keras_ocr) (2.31.6)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet==1.0.0->keras_ocr) (3.9.0)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (3.3)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (2024.5.10)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->efficientnet==1.0.0->keras_ocr) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->imgaug->keras_ocr) (2.8.2)\n",
            "Installing collected packages: pyclipper, essential_generators, validators, keras-applications, efficientnet, keras_ocr\n",
            "Successfully installed efficientnet-1.0.0 essential_generators-1.0 keras-applications-1.0.8 keras_ocr-0.9.3 pyclipper-1.3.0.post5 validators-0.28.1\n"
          ]
        }
      ],
      "source": [
        "!pip install keras_ocr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Y6z6bmisNCCR"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import keras_ocr\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MIADYnKhHTGg"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using OCR"
      ],
      "metadata": {
        "id": "_Tad27pw5BS-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import math\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras_ocr\n",
        "\n",
        "def midpoint(x1, y1, x2, y2):\n",
        "    return int((x1 + x2) / 2), int((y1 + y2) / 2)\n",
        "\n",
        "def inpaint_text(input_folder_path, output_folder_path='output_folder', max_text_regions=4):\n",
        "    # Create the output folder if it doesn't exist\n",
        "    if not os.path.exists(output_folder_path):\n",
        "        os.makedirs(output_folder_path)\n",
        "\n",
        "    # Initialize Keras OCR pipeline\n",
        "    pipeline = keras_ocr.pipeline.Pipeline()\n",
        "\n",
        "    # Iterate over the files in the input folder\n",
        "    for filename in os.listdir(input_folder_path):\n",
        "        # Check if the file is an image (you may want to add more file extensions)\n",
        "        if filename.endswith(('.jpg', '.jpeg', '.png', '.bmp')):\n",
        "            # Read the image in color\n",
        "            img_path = os.path.join(input_folder_path, filename)\n",
        "            img = cv2.imread(img_path)\n",
        "\n",
        "            # Perform text detection\n",
        "            prediction_groups = pipeline.recognize([img])\n",
        "\n",
        "            # Create a mask for text regions\n",
        "            mask = np.zeros(img.shape[:2], dtype=\"uint8\")\n",
        "            for idx, box in enumerate(prediction_groups[0]):\n",
        "                if idx >= max_text_regions:\n",
        "                    break  # Limit the number of text regions processed\n",
        "                x0, y0 = box[1][0]\n",
        "                x1, y1 = box[1][1]\n",
        "                x2, y2 = box[1][2]\n",
        "                x3, y3 = box[1][3]\n",
        "\n",
        "                x_mid0, y_mid0 = midpoint(x1-100, y1-100, x2+100, y2+100)\n",
        "                x_mid1, y_mid1 = midpoint(x0+100, y0+100, x3-100, y3-100)\n",
        "\n",
        "                thickness = int(math.sqrt((x2 - x1)**2 + (y2 - y1)**2) + 20)\n",
        "\n",
        "                cv2.line(mask, (x_mid0, y_mid0), (x_mid1, y_mid1), 255, thickness)\n",
        "\n",
        "            # Inpaint text regions\n",
        "            inpainted_img = cv2.inpaint(img, mask, 10, cv2.INPAINT_NS)\n",
        "\n",
        "            # Save the inpainted image to the output folder\n",
        "            output_img_path = os.path.join(output_folder_path, filename)\n",
        "            cv2.imwrite(output_img_path, inpainted_img)\n",
        "            print(f\"Processed image saved: {output_img_path}\")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "on-JluJ65ACZ",
        "outputId": "dfacf104-a41f-47ce-a72f-27d46b0c82a7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking for /root/.keras-ocr/craft_mlt_25k.h5\n",
            "Looking for /root/.keras-ocr/crnn_kurapan.h5\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "Processed image saved: output_folder1/15.jpg\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x79f6749f93f0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 4s 4s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "Processed image saved: output_folder1/48.jpg\n",
            "1/1 [==============================] - 47s 47s/step\n",
            "1/1 [==============================] - 6s 6s/step\n",
            "Processed image saved: output_folder1/55.jpg\n",
            "1/1 [==============================] - 17s 17s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "Processed image saved: output_folder1/51.jpg\n",
            "1/1 [==============================] - 18s 18s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "Processed image saved: output_folder1/2.jpg\n",
            "1/1 [==============================] - 2s 2s/step\n",
            "1/1 [==============================] - 4s 4s/step\n",
            "Processed image saved: output_folder1/21.jpg\n",
            "1/1 [==============================] - 43s 43s/step\n",
            "1/1 [==============================] - 3s 3s/step\n",
            "Processed image saved: output_folder1/9.jpg\n",
            "1/1 [==============================] - 45s 45s/step\n",
            "1/1 [==============================] - 7s 7s/step\n",
            "Processed image saved: output_folder1/52.jpg\n",
            "1/1 [==============================] - 45s 45s/step\n",
            "1/1 [==============================] - 5s 5s/step\n",
            "Processed image saved: output_folder1/44.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using"
      ],
      "metadata": {
        "id": "bypa2Drq-nnt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage:\n",
        "input_folder_path = 'ids'\n",
        "output_folder_path = 'output_folder1'\n",
        "inpaint_text(input_folder_path, output_folder_path)"
      ],
      "metadata": {
        "id": "PYe79hvS-mbq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SIFT"
      ],
      "metadata": {
        "id": "4GdV2FbgzKpC"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2rs3n-0DFWM",
        "outputId": "13d12f36-ccd6-4d33-9ecf-54209fe85e88"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed 15.jpg and saved to output_folder/15.jpg\n",
            "Processed 48.jpg and saved to output_folder/48.jpg\n",
            "Processed 55.jpg and saved to output_folder/55.jpg\n",
            "Processed 51.jpg and saved to output_folder/51.jpg\n",
            "Processed 2.jpg and saved to output_folder/2.jpg\n",
            "Processed 21.jpg and saved to output_folder/21.jpg\n",
            "Processed 9.jpg and saved to output_folder/9.jpg\n",
            "Processed 52.jpg and saved to output_folder/52.jpg\n",
            "Processed 44.jpg and saved to output_folder/44.jpg\n",
            "Processing completed for all images.\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def remove_logo_from_images(input_folder, output_folder ):\n",
        "    # Initialize feature detectors\n",
        "    sift = cv2.SIFT_create()\n",
        "    orb = cv2.ORB_create()\n",
        "    logo_path ='logo.jpg'\n",
        "    # Read the logo image\n",
        "    logo_image = cv2.imread(logo_path)\n",
        "    gray_logo = cv2.cvtColor(logo_image, cv2.COLOR_BGR2GRAY)\n",
        "    gray_logo = cv2.GaussianBlur(gray_logo, (5, 5), 0)\n",
        "    gray_logo = cv2.equalizeHist(gray_logo)\n",
        "\n",
        "    # Compute descriptors for the logo\n",
        "    kp_logo, des_logo = sift.detectAndCompute(gray_logo, None)\n",
        "    kp_logo_orb, des_logo_orb = orb.detectAndCompute(gray_logo, None)\n",
        "\n",
        "    # Create FLANN matcher for SIFT\n",
        "    FLANN_INDEX_KDTREE = 1\n",
        "    index_params = dict(algorithm=FLANN_INDEX_KDTREE, trees=5)\n",
        "    search_params = dict(checks=50)\n",
        "    flann = cv2.FlannBasedMatcher(index_params, search_params)\n",
        "\n",
        "    # Create BFMatcher for ORB\n",
        "    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)\n",
        "\n",
        "    # Process each image in the input folder\n",
        "    for filename in os.listdir(input_folder):\n",
        "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
        "            image_path = os.path.join(input_folder, filename)\n",
        "            image = cv2.imread(image_path)\n",
        "            gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "            gray_image = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
        "            gray_image = cv2.equalizeHist(gray_image)\n",
        "\n",
        "            # Compute descriptors for the image\n",
        "            kp_image, des_image = sift.detectAndCompute(gray_image, None)\n",
        "            kp_image_orb, des_image_orb = orb.detectAndCompute(gray_image, None)\n",
        "\n",
        "            # Match SIFT descriptors\n",
        "            matches = flann.knnMatch(des_logo, des_image, k=2)\n",
        "            good_matches = [m for m, n in matches if m.distance < 0.6 * n.distance]\n",
        "\n",
        "            # Match ORB descriptors\n",
        "            matches_orb = bf.match(des_logo_orb, des_image_orb)\n",
        "            good_matches_orb = sorted(matches_orb, key=lambda x: x.distance)\n",
        "\n",
        "            # Combine good matches from both descriptors\n",
        "            good_matches_combined = good_matches + good_matches_orb[:min(len(good_matches_orb), len(good_matches))]\n",
        "\n",
        "            if len(good_matches_combined) > 10:\n",
        "                # Extract locations of good matches\n",
        "                src_pts = np.float32([kp_logo[m.queryIdx].pt for m in good_matches_combined if m.queryIdx < len(kp_logo)]).reshape(-1, 1, 2)\n",
        "                dst_pts = np.float32([kp_image[m.trainIdx].pt for m in good_matches_combined if m.trainIdx < len(kp_image)]).reshape(-1, 1, 2)\n",
        "\n",
        "                # Compute homography\n",
        "                M, mask = cv2.findHomography(src_pts, dst_pts, cv2.RANSAC, 3.0)\n",
        "                h, w, _ = logo_image.shape\n",
        "\n",
        "                # Get coordinates of the logo in the target image\n",
        "                pts = np.float32([[0, 0], [0, h-1], [w-1, h-1], [w-1, 0]]).reshape(-1, 1, 2)\n",
        "                dst = cv2.perspectiveTransform(pts, M)\n",
        "\n",
        "                # Mask the logo area\n",
        "                logo_mask = np.zeros_like(gray_image)\n",
        "                cv2.fillPoly(logo_mask, [np.int32(dst)], 255)\n",
        "\n",
        "                # Inpaint the logo area\n",
        "                result = cv2.inpaint(image, logo_mask, 3, cv2.INPAINT_TELEA)\n",
        "\n",
        "                # Save the result in the output folder\n",
        "                output_path = os.path.join(output_folder, filename)\n",
        "                cv2.imwrite(output_path, result)\n",
        "                print(f\"Processed {filename} and saved to {output_path}\")\n",
        "\n",
        "    print(\"Processing completed for all images.\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j57ba__J0-QO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# using"
      ],
      "metadata": {
        "id": "pZvuUbKhz_dx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OWtC2796ELlG"
      },
      "outputs": [],
      "source": [
        "# Example usage\n",
        "input_folder = 'ids'\n",
        "output_folder = 'output_folder'\n",
        "remove_logo_from_images(input_folder, output_folder)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EyTnonCVK1qM"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0YhseB6sMQNB"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIMUE2CWNGA8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZD_TV8nJTDk_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}